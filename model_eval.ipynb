{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LambdaCallback\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "\n",
    "from utils.label_utils import get_labels, get_train_labels\n",
    "from models.u2net import U2NET, U2NET_lite\n",
    "from models.deeplabv3_xception import deeplabv3\n",
    "\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "K.clear_session()\n",
    "\n",
    "def enable_amp():\n",
    "    mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    \n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(physical_devices,\"\\n\")\n",
    "enable_amp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('ggplot')\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(serialized_example):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature((), tf.string),\n",
    "        'segmentation': tf.io.FixedLenFeature((), tf.string),\n",
    "        'height': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'width': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'image_depth': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'mask_depth': tf.io.FixedLenFeature((), tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "    image = tf.io.parse_tensor(example['image'], out_type = tf.uint8)\n",
    "    image_shape = [example['height'], example['width'], 3]\n",
    "    image = tf.reshape(image, image_shape)\n",
    "    mask = tf.io.parse_tensor(example['segmentation'], out_type = tf.uint8)\n",
    "    mask_shape = [example['height'], example['width'], 1]\n",
    "    mask = tf.reshape(mask, mask_shape)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def get_dataset_from_tfrecord(tfrecord_dir):\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(tfrecord_dir)\n",
    "    parsed_dataset = tfrecord_dataset.map(read_tfrecord)\n",
    "    return parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecord_dir = 'records/fine_train.tfrecords'\n",
    "test_tfrecord_dir = 'records/fine_test.tfrecords'\n",
    "\n",
    "img_height = 256\n",
    "img_width = 512\n",
    "n_classes = 19\n",
    "\n",
    "labels = get_train_labels()\n",
    "id2label = { label.id : label for label in labels }\n",
    "trainId2label = { label.trainId : label for label in labels }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def mask_to_categorical(image, mask):\n",
    "    mask = tf.squeeze(mask)\n",
    "    mask = tf.one_hot(tf.cast(mask, tf.int32), n_classes)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def load_image_train(input_image, input_mask):\n",
    "    input_image = tf.image.resize(input_image, (img_height, img_width))\n",
    "    input_mask = tf.image.resize(input_mask, (img_height, img_width))\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_image, input_mask = mask_to_categorical(input_image, input_mask)\n",
    "    input_mask = tf.squeeze(input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "\n",
    "def load_image_test(input_image, input_mask):\n",
    "    input_image = tf.image.resize(input_image, (img_height, img_width))\n",
    "    input_mask = tf.image.resize(input_mask, (img_height, img_width))\n",
    "    \n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_image, input_mask = mask_to_categorical(input_image, input_mask)\n",
    "    input_mask = tf.squeeze(input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = 2780\n",
    "TEST_LENGTH = 695\n",
    "BATCH_SIZE = 4\n",
    "BUFFER_SIZE = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecords_dataset = get_dataset_from_tfrecord(train_tfrecord_dir)\n",
    "test_tfrecords_dataset = get_dataset_from_tfrecord(test_tfrecord_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: resize the images and masks, flip them, \n",
    "train = train_tfrecords_dataset.map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test = test_tfrecords_dataset.map(load_image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_rgb(mask):\n",
    "    mask_rgb = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "    for i in range(0,n_classes):\n",
    "        mask_rgb[mask[:,:,0]==i] = trainId2label[i].color\n",
    "        #mask_rgb[mask[:,:,0]==i] = id2label[i].color\n",
    "    return mask_rgb\n",
    "\n",
    "\n",
    "def display(display_list, title=False):\n",
    "    plt.figure(figsize=(14, 21))\n",
    "    # plt.figure(figsize=(6, 9))\n",
    "    if title:\n",
    "        title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(len(display_list), 1, i+1)\n",
    "        if title:\n",
    "            plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in test.take(8):\n",
    "    sample_image, sample_mask = image, mask\n",
    "    \n",
    "print(sample_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mask = tf.argmax(sample_mask, axis=-1)\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_small(input_height, input_width, n_classes = 3, act=\"relu\"):\n",
    "    \n",
    "    img_input = tf.keras.layers.Input(shape=(input_height, input_width, 3))\n",
    "\n",
    "    # -------------------------- Encoder --------------------------\n",
    "    \n",
    "    c1 = Conv2D(32, 3, padding='same', activation=act)(img_input)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = Conv2D(32, 3, padding='same', activation=act)(c1)\n",
    "    p1 = MaxPooling2D((2,2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(64, 3, padding='same', activation=act)(p1)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = Conv2D(64, 3, padding='same', activation=act)(c2)\n",
    "    p2 = MaxPooling2D((2,2))(c2)\n",
    "    p2 = Dropout(0.1)(p2)\n",
    "    \n",
    "    c3 = Conv2D(128, 3, padding='same', activation=act)(p2)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = Conv2D(128, 3, padding='same', activation=act)(c3)\n",
    "    p3 = MaxPooling2D((2,2))(c3)\n",
    "    p3 = Dropout(0.1)(p3)\n",
    "    \n",
    "    c4 = Conv2D(256, 3, padding='same', activation=act)(p3)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = Conv2D(256, 3, padding='same', activation=act)(c4)\n",
    "    p4 = MaxPooling2D((2,2))(c4)\n",
    "    p4 = Dropout(0.2)(p4)\n",
    "    \n",
    "    # ------------------------ Bottleneck -------------------------\n",
    "    \n",
    "    c5 = Conv2D(512, 3, padding='same', activation=act)(p4)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = Conv2D(512, 3, padding='same', activation=act)(c5)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    \n",
    "    # -------------------------- Decoder --------------------------\n",
    "    \n",
    "    u6 = concatenate([UpSampling2D(2)(c5), c4])\n",
    "    c6 = Conv2D(256, 3, padding='same', activation=act)(u6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Conv2D(128, 3, padding='same', activation=act)(c6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    \n",
    "    u7 = concatenate([UpSampling2D(2)(c6), c3])\n",
    "    c7 = Conv2D(128, 3, padding='same', activation=act)(u7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Conv2D(64, 3, padding='same', activation=act)(c7)\n",
    "    c7 = Dropout(0.1)(c7)\n",
    "\n",
    "    u8 = concatenate([UpSampling2D(2)(c7), c2])\n",
    "    c8 = Conv2D(64, 3, padding='same', activation=act)(u8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Conv2D(32, 3, padding='same', activation=act)(c8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "\n",
    "    u9 = concatenate([UpSampling2D(2)(c8), c1]) \n",
    "    c9 = Conv2D(32, 3, padding='same', activation=act)(u9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = Conv2D(32, 3, padding='same', activation=act)(c9)\n",
    "    c9 = Conv2D(n_classes, 3, padding='same')(c9)\n",
    "    \n",
    "    output = Activation(\"softmax\", dtype='float32')(c9)\n",
    "    \n",
    "    return tf.keras.Model(inputs=img_input, outputs=output)\n",
    "\n",
    "\n",
    "\n",
    "def unet(input_height, input_width, n_classes = 3, act=\"relu\"):\n",
    "    \n",
    "    img_input = tf.keras.layers.Input(shape=(input_height, input_width, 3))\n",
    "\n",
    "    # -------------------------- Encoder --------------------------\n",
    "    \n",
    "    c1 = Conv2D(64, 3, padding='same', activation=act)(img_input)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = Conv2D(64, 3, padding='same', activation=act)(c1)\n",
    "    p1 = MaxPooling2D((2,2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(128, 3, padding='same', activation=act)(p1)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = Conv2D(128, 3, padding='same', activation=act)(c2)\n",
    "    p2 = MaxPooling2D((2,2))(c2)\n",
    "\n",
    "    \n",
    "    c3 = Conv2D(256, 3, padding='same', activation=act)(p2)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = Conv2D(256, 3, padding='same', activation=act)(c3)\n",
    "    p3 = MaxPooling2D((2,2))(c3)\n",
    "    p3 = Dropout(0.1)(p3)\n",
    "    \n",
    "    c4 = Conv2D(512, 3, padding='same', activation=act)(p3)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = Conv2D(512, 3, padding='same', activation=act)(c4)\n",
    "    p4 = MaxPooling2D((2,2))(c4)\n",
    "    p4 = Dropout(0.2)(p4)\n",
    "    \n",
    "    # ------------------------ Bottleneck -------------------------\n",
    "    \n",
    "    c5 = Conv2D(1024, 3, padding='same', activation=act)(p4)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = Conv2D(1024, 3, padding='same', activation=act)(c5)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    \n",
    "    # -------------------------- Decoder --------------------------\n",
    "    \n",
    "    u6 = concatenate([UpSampling2D(2)(c5), c4])\n",
    "    c6 = Conv2D(512, 3, padding='same', activation=act)(u6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Conv2D(256, 3, padding='same', activation=act)(c6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    \n",
    "    u7 = concatenate([UpSampling2D(2)(c6), c3])\n",
    "    c7 = Conv2D(256, 3, padding='same', activation=act)(u7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Conv2D(128, 3, padding='same', activation=act)(c7)\n",
    "    c7 = Dropout(0.1)(c7)\n",
    "\n",
    "    u8 = concatenate([UpSampling2D(2)(c7), c2])\n",
    "    c8 = Conv2D(128, 3, padding='same', activation=act)(u8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Conv2D(64, 3, padding='same', activation=act)(c8)\n",
    "\n",
    "\n",
    "    u9 = concatenate([UpSampling2D(2)(c8), c1]) \n",
    "    c9 = Conv2D(64, 3, padding='same', activation=act)(u9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = Conv2D(64, 3, padding='same', activation=act)(c9)\n",
    "    c9 = Conv2D(n_classes, 3, padding='same')(c9)\n",
    "    \n",
    "    output = Activation(\"softmax\", dtype='float32')(c9)\n",
    "    \n",
    "    return tf.keras.Model(inputs=img_input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_coef(y_true, y_pred):\n",
    "    \"\"\"When smooth=1, metrics where absent classes contribute to the class mean as 1.0. \n",
    "       Road is trainId == 0, but \"unlabeled\" is Id == 0. So start from zero when training with trainId\n",
    "       intersection and union shapes are batch_size * n_classes (values = area in pixels)\"\"\"\n",
    "    smooth = 1.0\n",
    "    intersection = K.sum(y_true * y_pred, axis=(1,2))\n",
    "    mask_sum = K.sum(y_true, axis=(1,2)) + K.sum(y_pred, axis=(1,2))\n",
    "    union = mask_sum - intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth))\n",
    "    return iou\n",
    "\n",
    "\n",
    "def cce_iou_loss(y_true, y_pred):\n",
    "    return (tf.keras.losses.categorical_crossentropy(y_true, y_pred) - iou_coef(y_true, y_pred)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# model = unet(input_height=img_height, input_width=img_width, n_classes=n_classes, act=\"selu\")\n",
    "# model = unet_small(input_height=img_height, input_width=img_width, n_classes=n_classes, act=\"relu\")\n",
    "model = U2NET(input_height=img_height, input_width=img_width, n_classes=n_classes)\n",
    "# model = U2NET_lite(input_height=img_height, input_width=img_width, n_classes=n_classes)\n",
    "# model = deeplabv3(input_height=img_height, input_width=img_width, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u2net_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.squeeze(pred_mask)\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    pred_mask = label_to_rgb(pred_mask.numpy())\n",
    "    return pred_mask\n",
    "\n",
    "\n",
    "def show_predictions(u2net=False):\n",
    "    pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
    "    if u2net:\n",
    "        pred_mask = pred_mask[0]\n",
    "    display([sample_image, sample_mask, create_mask(pred_mask)])\n",
    "\n",
    "        \n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions(u2net=u2net_model)\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(u2net=u2net_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(lr=1e-4),\n",
    "    loss = cce_iou_loss, \n",
    "    metrics = ['accuracy', iou_coef]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    DisplayCallback(),\n",
    "    EarlyStopping(monitor='val_loss', mode='min', patience=6, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', mode='min', patience=3, factor=0.1, min_lr=1e-10, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "SUBSPLITS = 5\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE // SUBSPLITS\n",
    "VALIDATION_STEPS = TEST_LENGTH // BATCH_SIZE // SUBSPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    epochs = (EPOCHS*SUBSPLITS),\n",
    "    validation_data = test_dataset,\n",
    "    callbacks = callbacks,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(results, u2net=False):\n",
    "    \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.subplot(1,3,1)  \n",
    "    if u2net:\n",
    "        plt.plot(results.history['d0_loss'], 'r', label='Training loss')\n",
    "        plt.plot(results.history['val_d0_loss'], 'b', label='Validation loss')\n",
    "    else: \n",
    "        plt.plot(results.history['loss'], 'r', label='Training loss')\n",
    "        plt.plot(results.history['val_loss'], 'b', label='Validation loss')\n",
    "    plt.title('Log Loss', fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    if u2net:\n",
    "        plt.plot(results.history['d0_accuracy'], 'r', label='Training accuracy')\n",
    "        plt.plot(results.history['val_d0_accuracy'], 'b', label='Validation accuracy')\n",
    "    else:\n",
    "        plt.plot(results.history['accuracy'], 'r', label='Training accuracy')\n",
    "        plt.plot(results.history['val_accuracy'], 'b', label='Validation accuracy')\n",
    "    plt.title('Accuracy', fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    if u2net:\n",
    "        plt.plot(results.history['d0_iou_coef'], 'r', label='IoU coefficient')\n",
    "        plt.plot(results.history['val_d0_iou_coef'], 'b', label='Validation IoU coefficient')\n",
    "    else:\n",
    "        plt.plot(results.history['iou_coef'], 'r', label='IoU coefficient')\n",
    "        plt.plot(results.history['val_iou_coef'], 'b', label='Validation IoU coefficient')\n",
    "    plt.title('IoU Coefficient', fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(results, u2net=u2net_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_iou(y_true, y_pred):\n",
    "    \"\"\" Absent classes contribute to the class mean as 1.0 \"\"\"\n",
    "    iou = 0.0\n",
    "    smooth = 1.0\n",
    "    iou_class = []\n",
    "    for i in range(0, n_classes):\n",
    "        intersection = K.sum(y_true[:,:,:,i] * y_pred[:,:,:,i], axis=(1,2))\n",
    "        union = K.sum(y_true[:,:,:,i] + y_pred[:,:,:,i], axis=(1,2)) - intersection\n",
    "        iou_temp = K.mean((intersection + smooth) / (union + smooth))\n",
    "        iou_class.append(iou_temp.numpy())\n",
    "        iou = iou + iou_temp\n",
    "    iou_mean = iou / n_classes\n",
    "    return iou_class, iou_mean.numpy()\n",
    "\n",
    "\n",
    "def evaluate_iou(model, dataset, n_samples, u2net=False):\n",
    "    \n",
    "    iou_class_scores = np.zeros((n_samples, n_classes))\n",
    "    iou_mean_scores = np.zeros((n_samples,))\n",
    "    \n",
    "    for idx, (image, mask) in enumerate(dataset):\n",
    "        print(\"\\r Predicting {} \\ {} \".format(idx+1, n_samples), end='')\n",
    "        \n",
    "        X = image.numpy()\n",
    "        y_true = np.expand_dims(mask.numpy(), axis=0)\n",
    "        y_pred = model.predict(np.expand_dims(X, axis=0))\n",
    "        if u2net:\n",
    "            y_pred = y_pred[0]\n",
    "        \n",
    "        iou_class, iou_mean = get_mean_iou(y_true, y_pred)\n",
    "        iou_class_scores[idx] = iou_class\n",
    "        iou_mean_scores[idx] = iou_mean\n",
    "        \n",
    "        if idx == (n_samples-1):\n",
    "            break\n",
    "            \n",
    "    return np.mean(iou_class_scores, axis=0), np.mean(iou_mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_class, iou_mean = evaluate_iou(model=model, dataset=test, n_samples=TEST_LENGTH, u2net=u2net_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IoU Score: {:.4f}\".format(iou_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best IoU: 0.4009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iou(trainId2label, n_classes, iou_class):\n",
    "    categories = [trainId2label[i].category for i in range(n_classes)]\n",
    "    cmap = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "    cat_colors = {\n",
    "        'void': 'black',\n",
    "        'flat': cmap[0],\n",
    "        'construction': cmap[1],\n",
    "        'object': cmap[2],\n",
    "        'nature': cmap[3],\n",
    "        'sky': cmap[4],\n",
    "        'human': cmap[5],\n",
    "        'vehicle': cmap[6]\n",
    "    }\n",
    "    colors = [cat_colors[category] for category in categories]\n",
    "\n",
    "    names = [trainId2label[i].name for i in range(n_classes)]\n",
    "\n",
    "    plt.figure(figsize=(14,10), dpi=200)\n",
    "    plt.barh(names, iou_class, color=colors)\n",
    "    plt.xlabel(\"IoU Coefficient\", fontsize=18)\n",
    "    plt.ylabel(\"Class Name\", fontsize=18)\n",
    "    plt.title(\"Class IoU Score\", fontsize=22)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iou(trainId2label=trainId2label, n_classes=n_classes, iou_class=iou_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
