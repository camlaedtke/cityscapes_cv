{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LambdaCallback\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "from utils.label_utils import get_labels, get_train_labels\n",
    "from models.u2net import U2NET, U2NET_lite\n",
    "from models.unet import unet, unet_small\n",
    "from models.deeplabv3_xception import deeplabv3\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "K.clear_session()\n",
    "\n",
    "def enable_amp():\n",
    "    mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    \n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(physical_devices,\"\\n\")\n",
    "enable_amp() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('ggplot')\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(serialized_example):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature((), tf.string),\n",
    "        'segmentation': tf.io.FixedLenFeature((), tf.string),\n",
    "        'height': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'width': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'image_depth': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'mask_depth': tf.io.FixedLenFeature((), tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "    image = tf.io.parse_tensor(example['image'], out_type = tf.uint8)\n",
    "    image_shape = [example['height'], example['width'], 3]\n",
    "    image = tf.reshape(image, image_shape)\n",
    "    mask = tf.io.parse_tensor(example['segmentation'], out_type = tf.uint8)\n",
    "    mask_shape = [example['height'], example['width'], 1]\n",
    "    mask = tf.reshape(mask, mask_shape)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def get_dataset_from_tfrecord(tfrecord_dir):\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(tfrecord_dir)\n",
    "    parsed_dataset = tfrecord_dataset.map(read_tfrecord)\n",
    "    return parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine = True\n",
    "\n",
    "if fine:\n",
    "    train_tfrecord_dir = 'records/fine_train_cat.tfrecords'\n",
    "    test_tfrecord_dir = 'records/fine_test_cat.tfrecords'\n",
    "else:\n",
    "    train_tfrecord_dir = 'records/coarse_train.tfrecords'\n",
    "    test_tfrecord_dir = 'records/coarse_test.tfrecords'\n",
    "\n",
    "\n",
    "img_height = 256\n",
    "img_width = 512\n",
    "n_classes = 8\n",
    "\n",
    "# labels = get_train_labels()\n",
    "labels = get_labels()\n",
    "id2label = { label.id : label for label in labels }\n",
    "trainId2label = { label.trainId : label for label in labels }\n",
    "catId2label = { label.categoryId : label for label in labels }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the `@tf.function` decorator supposedly makes things faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def mask_to_categorical(image, mask):\n",
    "    mask = tf.squeeze(mask) \n",
    "    mask = tf.one_hot(tf.cast(mask, tf.int32), n_classes)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def load_image_train(input_image, input_mask):\n",
    "    input_image = tf.image.resize(input_image, (img_height, img_width))\n",
    "    input_mask = tf.image.resize(input_mask, (img_height, img_width))\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_image, input_mask = mask_to_categorical(input_image, input_mask)\n",
    "    input_mask = tf.squeeze(input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "\n",
    "def load_image_test(input_image, input_mask):\n",
    "    input_image = tf.image.resize(input_image, (img_height, img_width))\n",
    "    input_mask = tf.image.resize(input_mask, (img_height, img_width))\n",
    "    \n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_image, input_mask = mask_to_categorical(input_image, input_mask)\n",
    "    input_mask = tf.squeeze(input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine:\n",
    "    TRAIN_LENGTH = 2780\n",
    "    TEST_LENGTH = 695\n",
    "else:\n",
    "    TRAIN_LENGTH = 16000\n",
    "    TEST_LENGTH = 3998\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecords_dataset = get_dataset_from_tfrecord(train_tfrecord_dir)\n",
    "test_tfrecords_dataset = get_dataset_from_tfrecord(test_tfrecord_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: resize the images and masks, flip them, \n",
    "train = train_tfrecords_dataset.map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test = test_tfrecords_dataset.map(load_image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_rgb(mask):\n",
    "    mask_rgb = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "    for i in range(0, n_classes):\n",
    "        #mask_rgb[mask[:,:,0]==i] = trainId2label[i].color \n",
    "        mask_rgb[mask[:,:,0]==i] = catId2label[i].color\n",
    "        #mask_rgb[mask[:,:,0]==i] = id2label[i].color \n",
    "    return mask_rgb\n",
    "\n",
    "\n",
    "def display(display_list, title=False):\n",
    "    plt.figure(figsize=(14, 21))\n",
    "    # plt.figure(figsize=(6, 9))\n",
    "    if title:\n",
    "        title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(len(display_list), 1, i+1)\n",
    "        if title:\n",
    "            plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in train.take(1):\n",
    "    sample_image, sample_mask = image, mask\n",
    "    \n",
    "sample_mask = tf.argmax(sample_mask, axis=-1)\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard way to train an image segmentation model is using categorical crossentropy loss. This works okay, but it has the drawback of being biased towards classes that are generally larger in the image (ex: roads, trees). So here we define a custom loss function that combines the categorical crossentropy and the average IoU coefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_coef(y_true, y_pred):\n",
    "    \"\"\"When smooth=1, metrics where absent classes contribute to the class mean as 1.0.\"\"\"\n",
    "    smooth = 1.0\n",
    "    intersection = K.sum(y_true * y_pred, axis=(1,2))\n",
    "    mask_sum = K.sum(y_true, axis=(1,2)) + K.sum(y_pred, axis=(1,2))\n",
    "    union = mask_sum - intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth))\n",
    "    return iou\n",
    "\n",
    "\n",
    "def cce_iou_loss(y_true, y_pred):\n",
    "    return (tf.keras.losses.categorical_crossentropy(y_true, y_pred) - iou_coef(y_true, y_pred)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# model = unet(input_height=img_height, input_width=img_width, n_classes=n_classes, act=\"relu\")\n",
    "# model = unet_small(input_height=img_height, input_width=img_width, n_classes=n_classes, act=\"relu\")\n",
    "# model = U2NET(input_height=img_height, input_width=img_width, n_classes=n_classes)\n",
    "# model = U2NET_lite(input_height=img_height, input_width=img_width, n_classes=n_classes)\n",
    "model = deeplabv3(input_height=img_height, input_width=img_width, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To note: the U2Net model has six different outputs (for training), so the `model.predict()` function outputs a list of six tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.squeeze(pred_mask)\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    pred_mask = label_to_rgb(pred_mask.numpy())\n",
    "    return pred_mask\n",
    "\n",
    "\n",
    "def show_predictions():\n",
    "    pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
    "    if model.name == \"u2net\":\n",
    "        pred_mask = pred_mask[0]\n",
    "    display([sample_image, sample_mask, create_mask(pred_mask)])\n",
    "\n",
    "        \n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(lr=1e-4),\n",
    "    loss = cce_iou_loss, \n",
    "    metrics = ['accuracy', iou_coef]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    DisplayCallback(),\n",
    "    EarlyStopping(monitor='val_loss', mode='min', patience=8, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', mode='min', patience=4, factor=0.1, min_lr=1e-10, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "SUBSPLITS = 4\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE // SUBSPLITS\n",
    "VALIDATION_STEPS = TEST_LENGTH // BATCH_SIZE // SUBSPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_coarse = \"weights/\"+model.name+\"_coarse.h5\"\n",
    "PATH_fine = \"weights/\"+model.name+\".h5\"\n",
    "\n",
    "if os.path.isfile(PATH_coarse):\n",
    "    model.load_weights(PATH_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    epochs = (EPOCHS*SUBSPLITS),\n",
    "    validation_data = test_dataset,\n",
    "    callbacks = callbacks,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine:\n",
    "    model.save_weights(PATH_fine)\n",
    "else:\n",
    "    model.save_weights(PATH_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(results, model):\n",
    "        \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.subplot(1,3,1)  \n",
    "    if model.name == \"u2net\":\n",
    "        plt.plot(results.history['d0_loss'], 'r', label='Training loss')\n",
    "        plt.plot(results.history['val_d0_loss'], 'b', label='Validation loss')\n",
    "    else: \n",
    "        plt.plot(results.history['loss'], 'r', label='Training loss')\n",
    "        plt.plot(results.history['val_loss'], 'b', label='Validation loss')\n",
    "    plt.title(\"Log Loss: \"+model.name, fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    if model.name == \"u2net\":\n",
    "        plt.plot(results.history['d0_accuracy'], 'r', label='Training accuracy')\n",
    "        plt.plot(results.history['val_d0_accuracy'], 'b', label='Validation accuracy')\n",
    "    else:\n",
    "        plt.plot(results.history['accuracy'], 'r', label='Training accuracy')\n",
    "        plt.plot(results.history['val_accuracy'], 'b', label='Validation accuracy')\n",
    "    plt.title('Accuracy: '+model.name, fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    if model.name == \"u2net\":\n",
    "        plt.plot(results.history['d0_iou_coef'], 'r', label='IoU coefficient')\n",
    "        plt.plot(results.history['val_d0_iou_coef'], 'b', label='Validation IoU coefficient')\n",
    "    else:\n",
    "        plt.plot(results.history['iou_coef'], 'r', label='IoU coefficient')\n",
    "        plt.plot(results.history['val_iou_coef'], 'b', label='Validation IoU coefficient')\n",
    "    plt.title('IoU Coefficient: '+model.name, fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "    if fine:\n",
    "        plt.savefig(\"plots/\"+model.name+\"_learning_curves.png\")\n",
    "    else:\n",
    "        plt.savefig(\"plots/\"+model.name+\"_learning_curves.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_history(results, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_iou(y_true, y_pred):\n",
    "    \"\"\" Absent classes contribute to the class mean as 1.0 \"\"\"\n",
    "    iou = 0.0\n",
    "    smooth = 1.0\n",
    "    iou_class = []\n",
    "    for i in range(1, n_classes):\n",
    "        intersection = K.sum(y_true[:,:,:,i] * y_pred[:,:,:,i], axis=(1,2))\n",
    "        union = K.sum(y_true[:,:,:,i] + y_pred[:,:,:,i], axis=(1,2)) - intersection\n",
    "        iou_temp = K.mean((intersection + smooth) / (union + smooth))\n",
    "        iou_class.append(iou_temp.numpy())\n",
    "        iou = iou + iou_temp\n",
    "    iou_mean = iou / n_classes\n",
    "    return iou_class, iou_mean.numpy()\n",
    "\n",
    "\n",
    "def evaluate_iou(model, dataset, n_samples):\n",
    "    \n",
    "    iou_class_scores = np.zeros((n_samples, n_classes-1))\n",
    "    iou_mean_scores = np.zeros((n_samples,))\n",
    "    \n",
    "    for idx, (image, mask) in enumerate(dataset):\n",
    "        print(\"\\r Predicting {} \\ {} \".format(idx+1, n_samples), end='')\n",
    "        \n",
    "        X = image.numpy()\n",
    "        y_true = np.expand_dims(mask.numpy(), axis=0)\n",
    "        y_pred = model.predict(np.expand_dims(X, axis=0))\n",
    "        if model.name == \"u2net\":\n",
    "            y_pred = y_pred[0]\n",
    "        \n",
    "        iou_class, iou_mean = get_mean_iou(y_true, y_pred)\n",
    "        iou_class_scores[idx] = iou_class\n",
    "        iou_mean_scores[idx] = iou_mean\n",
    "        \n",
    "        if idx == (n_samples-1):\n",
    "            break\n",
    "            \n",
    "    return np.mean(iou_class_scores, axis=0), np.mean(iou_mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_class, iou_mean = evaluate_iou(model=model, dataset=test, n_samples=TEST_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"IoU Score: {:.4f}\".format(iou_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Ids: Best IoU: 0.4250\n",
    "#### Category Ids: Best IoU: 0.5914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iou_trainId(Id2label, n_classes, iou_class, model):\n",
    "    categories = [Id2label[i].category for i in range(n_classes)]\n",
    "    cmap = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "    cat_colors = {\n",
    "        'void': 'black',\n",
    "        'flat': cmap[0],\n",
    "        'construction': cmap[1],\n",
    "        'object': cmap[2],\n",
    "        'nature': cmap[3],\n",
    "        'sky': cmap[4],\n",
    "        'human': cmap[5],\n",
    "        'vehicle': cmap[6]\n",
    "    }\n",
    "    colors = [cat_colors[category] for category in categories]\n",
    "\n",
    "    names = [Id2label[i].name for i in range(n_classes)]\n",
    "\n",
    "    plt.figure(figsize=(14,10), dpi=200)\n",
    "    plt.barh(names, iou_class, color=colors)\n",
    "    plt.xlabel(\"IoU Coefficient: \", fontsize=18)\n",
    "    plt.ylabel(\"Class Name\", fontsize=18)\n",
    "    plt.title(\"Class IoU Score: \"+model.name, fontsize=22)\n",
    "    plt.xlim([0, 1])\n",
    "    if fine:\n",
    "        plt.savefig(\"plots/\"+model.name+\"_iou_scores.png\")\n",
    "    else:\n",
    "        plt.savefig(\"plots/\"+model.name+\"_iou_scores_coarse.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_iou_catId(Id2label, n_classes, iou_class, model, iou_mean):\n",
    "    categories = [Id2label[i+1].category for i in range(n_classes-1)]\n",
    "    cmap = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "    cat_colors = {\n",
    "        'void': 'black',\n",
    "        'flat': cmap[0],\n",
    "        'construction': cmap[1],\n",
    "        'object': cmap[2],\n",
    "        'nature': cmap[3],\n",
    "        'sky': cmap[4],\n",
    "        'human': cmap[5],\n",
    "        'vehicle': cmap[6]\n",
    "    }\n",
    "    colors = [cat_colors[category] for category in categories]\n",
    "\n",
    "    plt.figure(figsize=(14,10), dpi=200)\n",
    "    plt.barh(categories, iou_class, color=colors)\n",
    "    plt.xlabel(\"IoU Coefficient\", fontsize=18)\n",
    "    plt.ylabel(\"Category Name\", fontsize=18)\n",
    "    plt.title(\"Category IoU Scores for {} - Average: {:.3f}\".format(model.name, iou_mean), fontsize=22)\n",
    "    plt.xlim([0, 1])\n",
    "    if fine:\n",
    "        plt.savefig(\"plots/\"+model.name+\"_iou_scores.png\")\n",
    "    else:\n",
    "        plt.savefig(\"plots/\"+model.name+\"_iou_scores_coarse.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_iou_trainId(Id2label=trainId2label, n_classes=n_classes, iou_class=iou_class, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iou_catId(Id2label=catId2label, n_classes=n_classes, iou_class=iou_class, model=model, iou_mean=iou_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
