{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division\n",
    "from collections import namedtuple\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LambdaCallback\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "from models.u2net import U2NET, U2NET_lite\n",
    "from models.unet import unet, unet_small\n",
    "from models.deeplabv3_xception import deeplabv3, deeplabv3_lite\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "K.clear_session()\n",
    "\n",
    "def enable_amp():\n",
    "    mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    \n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(physical_devices,\"\\n\")\n",
    "enable_amp() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('ggplot')\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "\n",
    "    # a label and all meta information\n",
    "    Label = namedtuple( 'Label' , [\n",
    "\n",
    "        'name'        , # The identifier of this label, e.g. 'car', 'person', ... .\n",
    "                        # We use them to uniquely name a class\n",
    "\n",
    "        'id'          , # An integer ID that is associated with this label.\n",
    "                        # The IDs are used to represent the label in ground truth images\n",
    "                        # An ID of -1 means that this label does not have an ID and thus\n",
    "                        # is ignored when creating ground truth images (e.g. license plate).\n",
    "                        # Do not modify these IDs, since exactly these IDs are expected by the\n",
    "                        # evaluation server.\n",
    "\n",
    "        'trainId'     , # Feel free to modify these IDs as suitable for your method. Then create\n",
    "                        # ground truth images with train IDs, using the tools provided in the\n",
    "                        # 'preparation' folder. However, make sure to validate or submit results\n",
    "                        # to our evaluation server using the regular IDs above!\n",
    "                        # For trainIds, multiple labels might have the same ID. Then, these labels\n",
    "                        # are mapped to the same class in the ground truth images. For the inverse\n",
    "                        # mapping, we use the label that is defined first in the list below.\n",
    "                        # For example, mapping all void-type classes to the same ID in training,\n",
    "                        # might make sense for some approaches.\n",
    "                        # Max value is 255!\n",
    "\n",
    "        'category'    , # The name of the category that this label belongs to\n",
    "\n",
    "        'categoryId'  , # The ID of this category. Used to create ground truth images\n",
    "                        # on category level.\n",
    "\n",
    "        'hasInstances', # Whether this label distinguishes between single instances or not\n",
    "\n",
    "        'ignoreInEval', # Whether pixels having this class as ground truth label are ignored\n",
    "                        # during evaluations or not\n",
    "\n",
    "        'color'       , # The color of this label\n",
    "        ] )\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------\n",
    "    # A list of all labels\n",
    "    #--------------------------------------------------------------------------------\n",
    "\n",
    "    # Please adapt the train IDs as appropriate for your approach.\n",
    "    # Note that you might want to ignore labels with ID 255 during training.\n",
    "    # Further note that the current train IDs are only a suggestion. You can use whatever you like.\n",
    "    # Make sure to provide your results using the original IDs and not the training IDs.\n",
    "    # Note that many IDs are ignored in evaluation and thus you never need to predict these!\n",
    "    \n",
    "    # Want to evaluate model on ids [7,8,11,12,13,17,19,20,21,22,23,24,25,26,27,28,31,32,33]\n",
    "\n",
    "    labels = [\n",
    "        #     name                    id  trainId  category         catId  hasInstances  ignoreInEval  color\n",
    "        Label('unlabeled'            , 0 ,    255 ,'void'          ,0      ,False       ,True         ,(  0,  0,  0)),\n",
    "        Label('ego vehicle'          , 1 ,    255 ,'void'          ,0      ,False       ,True         ,(  0,  0,  0)),\n",
    "        Label('rectification border' , 2 ,    255 ,'void'          ,0      ,False       ,True         ,(  0,  0,  0)),\n",
    "        Label('out of roi'           , 3 ,    255 ,'void'          ,0      ,False       ,True         ,(  0,  0,  0)),\n",
    "        Label('static'               , 4 ,    255 ,'void'          ,0      ,False       ,True         ,(  0,  0,  0)),\n",
    "        Label('dynamic'              , 5 ,    255 ,'void'          ,0      ,False       ,True         ,(111, 74,  0)),\n",
    "        Label('ground'               , 6 ,    255 ,'void'          ,0      ,False       ,True         ,( 81,  0, 81)),\n",
    "        Label('road'                 , 7 ,      0 ,'flat'          ,1      ,False       ,False        ,(128, 64,128)),\n",
    "        Label('sidewalk'             , 8 ,      1 ,'flat'          ,1      ,False       ,False        ,(244, 35,232)),\n",
    "        Label('parking'              , 9 ,    255 ,'flat'          ,0      ,False       ,True         ,(250,170,160)),\n",
    "        Label('rail track'           ,10 ,    255 ,'flat'          ,0      ,False       ,True         ,(230,150,140)),\n",
    "        Label('building'             ,11 ,      2 ,'construction'  ,2      ,False       ,False        ,( 70, 70, 70)),\n",
    "        Label('wall'                 ,12 ,      3 ,'construction'  ,2      ,False       ,False        ,(102,102,156)),\n",
    "        Label('fence'                ,13 ,      4 ,'construction'  ,2      ,False       ,False        ,(190,153,153)),\n",
    "        Label('guard rail'           ,14 ,    255 ,'construction'  ,0      ,False       ,True         ,(180,165,180)),\n",
    "        Label('bridge'               ,15 ,    255 ,'construction'  ,0      ,False       ,True         ,(150,100,100)),\n",
    "        Label('tunnel'               ,16 ,    255 ,'construction'  ,0      ,False       ,True         ,(150,120, 90)),\n",
    "        Label('pole'                 ,17 ,      5 ,'object'        ,3      ,False       ,False        ,(153,153,153)),\n",
    "        Label('polegroup'            ,18 ,    255 ,'object'        ,0      ,False       ,True         ,(153,153,153)),\n",
    "        Label('traffic light'        ,19 ,      6 ,'object'        ,3      ,False       ,False        ,(250,170, 30)),\n",
    "        Label('traffic sign'         ,20 ,      7 ,'object'        ,3      ,False       ,False        ,(220,220,  0)),\n",
    "        Label('vegetation'           ,21 ,      8 ,'nature'        ,4      ,False       ,False        ,(107,142, 35)),\n",
    "        Label('terrain'              ,22 ,      9 ,'nature'        ,4      ,False       ,False        ,(152,251,152)),\n",
    "        Label('sky'                  ,23 ,     10 ,'sky'           ,5      ,False       ,False        ,( 70,130,180)),\n",
    "        Label('person'               ,24 ,     11 ,'human'         ,6      ,True        ,False        ,(220, 20, 60)),\n",
    "        Label('rider'                ,25 ,     12 ,'human'         ,6      ,True        ,False        ,(255,  0,  0)),\n",
    "        Label('car'                  ,26 ,     13 ,'vehicle'       ,7      ,True        ,False        ,(  0,  0,142)),\n",
    "        Label('truck'                ,27 ,     14 ,'vehicle'       ,7      ,True        ,False        ,(  0,  0, 70)),\n",
    "        Label('bus'                  ,28 ,     15 ,'vehicle'       ,7      ,True        ,False        ,(  0, 60,100)),\n",
    "        Label('caravan'              ,29 ,    255 ,'vehicle'       ,0      ,True        ,True         ,(  0,  0, 90)),\n",
    "        Label('trailer'              ,30 ,    255 ,'vehicle'       ,0      ,True        ,True         ,(  0,  0,110)),\n",
    "        Label('train'                ,31 ,     16 ,'vehicle'       ,7      ,True        ,False        ,(  0, 80,100)),\n",
    "        Label('motorcycle'           ,32 ,     17 ,'vehicle'       ,7      ,True        ,False        ,(  0,  0,230)),\n",
    "        Label('bicycle'              ,33 ,     18 ,'vehicle'       ,7      ,True        ,False        ,(119, 11, 32)),\n",
    "        Label('license plate'        ,-1 ,     -1 ,'vehicle'       ,7      ,False       ,True         ,(  0,  0,142)),\n",
    "    ]\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(serialized_example):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature((), tf.string),\n",
    "        'segmentation': tf.io.FixedLenFeature((), tf.string),\n",
    "        'height': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'width': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'image_depth': tf.io.FixedLenFeature((), tf.int64),\n",
    "        'mask_depth': tf.io.FixedLenFeature((), tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(serialized_example, feature_description)\n",
    "    image = tf.io.parse_tensor(example['image'], out_type = tf.uint8)\n",
    "    image_shape = [example['height'], example['width'], 3]\n",
    "    image = tf.reshape(image, image_shape)\n",
    "    mask = tf.io.parse_tensor(example['segmentation'], out_type = tf.uint8)\n",
    "    mask_shape = [example['height'], example['width'], 1]\n",
    "    mask = tf.reshape(mask, mask_shape)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def get_dataset_from_tfrecord(tfrecord_dir):\n",
    "    tfrecord_dataset = tf.data.TFRecordDataset(tfrecord_dir)\n",
    "    parsed_dataset = tfrecord_dataset.map(read_tfrecord)\n",
    "    return parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine = True\n",
    "\n",
    "if fine:\n",
    "    train_tfrecord_dir = 'records/fine_train_cat.tfrecords'\n",
    "    test_tfrecord_dir = 'records/fine_test_cat.tfrecords'\n",
    "else:\n",
    "    train_tfrecord_dir = 'records/coarse_train_cat.tfrecords'\n",
    "    test_tfrecord_dir = 'records/coarse_test_cat.tfrecords'\n",
    "\n",
    "\n",
    "img_height = 512\n",
    "img_width = 1024\n",
    "n_classes = 8\n",
    "\n",
    "labels = get_labels()\n",
    "trainId2label = { label.trainId : label for label in labels }\n",
    "catId2label = { label.categoryId : label for label in labels }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the `@tf.function` decorator supposedly makes things faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def mask_to_categorical(image, mask):\n",
    "    mask = tf.squeeze(mask) \n",
    "    mask = tf.one_hot(tf.cast(mask, tf.int32), n_classes)\n",
    "    mask = tf.cast(mask, tf.float32)\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def load_image_train(input_image, input_mask):\n",
    "    input_image = tf.image.resize(input_image, (img_height, img_width))\n",
    "    input_mask = tf.image.resize(input_mask, (img_height, img_width))\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_image, input_mask = mask_to_categorical(input_image, input_mask)\n",
    "    input_mask = tf.squeeze(input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "\n",
    "def load_image_test(input_image, input_mask):\n",
    "    input_image = tf.image.resize(input_image, (img_height, img_width))\n",
    "    input_mask = tf.image.resize(input_mask, (img_height, img_width))\n",
    "    \n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    input_image, input_mask = mask_to_categorical(input_image, input_mask)\n",
    "    input_mask = tf.squeeze(input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine:\n",
    "    TRAIN_LENGTH = 2780\n",
    "    TEST_LENGTH = 695\n",
    "else:\n",
    "    TRAIN_LENGTH = 16000\n",
    "    TEST_LENGTH = 3998\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecords_dataset = get_dataset_from_tfrecord(train_tfrecord_dir)\n",
    "test_tfrecords_dataset = get_dataset_from_tfrecord(test_tfrecord_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: resize the images and masks, flip them, \n",
    "train = train_tfrecords_dataset.map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test = test_tfrecords_dataset.map(load_image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_rgb(mask):\n",
    "    mask_rgb = np.zeros((img_height, img_width, 3), dtype=np.uint8)\n",
    "    for i in range(0, n_classes):\n",
    "        #mask_rgb[mask[:,:,0]==i] = trainId2label[i].color \n",
    "        mask_rgb[mask[:,:,0]==i] = catId2label[i].color\n",
    "        #mask_rgb[mask[:,:,0]==i] = id2label[i].color \n",
    "    return mask_rgb\n",
    "\n",
    "\n",
    "def display(display_list, title=True):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    if title:\n",
    "        title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        if title:\n",
    "            plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in train.take(1):\n",
    "    sample_image, sample_mask = image, mask\n",
    "    \n",
    "sample_mask = tf.argmax(sample_mask, axis=-1)\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard way to train an image segmentation model is using categorical crossentropy loss. This works okay, but it has the drawback of being biased towards classes that are generally larger in the image (ex: roads, trees). So here we define a custom loss function that combines the categorical crossentropy and the average IoU coefficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_coef(y_true, y_pred):\n",
    "    \"\"\"When smooth=1, metrics where absent classes contribute to the class mean as 1.0.\"\"\"\n",
    "    smooth = 1.0\n",
    "    intersection = K.sum(y_true * y_pred, axis=(1,2))\n",
    "    mask_sum = K.sum(y_true, axis=(1,2)) + K.sum(y_pred, axis=(1,2))\n",
    "    union = mask_sum - intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth))\n",
    "    return iou\n",
    "\n",
    "\n",
    "def cce_iou_loss(y_true, y_pred):\n",
    "    return (tf.keras.losses.categorical_crossentropy(y_true, y_pred) - iou_coef(y_true, y_pred)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# model = unet(input_height=img_height, input_width=img_width, n_classes=n_classes, act=\"relu\")\n",
    "# model = unet_small(input_height=img_height, input_width=img_width, n_classes=n_classes, act=\"relu\")\n",
    "# model = U2NET(input_height=img_height, input_width=img_width, n_classes=n_classes)\n",
    "# model = U2NET_lite(input_height=img_height, input_width=img_width, n_classes=n_classes)\n",
    "# model = deeplabv3(input_height=img_height, input_width=img_width, n_classes=n_classes)\n",
    "model = deeplabv3_lite(input_height=img_height, input_width=img_width, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To note: the U2Net model has six different outputs (for training), so the `model.predict()` function outputs a list of six tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.squeeze(pred_mask)\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    pred_mask = label_to_rgb(pred_mask.numpy())\n",
    "    return pred_mask\n",
    "\n",
    "\n",
    "def show_predictions():\n",
    "    pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
    "    if model.name == \"u2net\":\n",
    "        pred_mask = pred_mask[0]\n",
    "    display([sample_image, sample_mask, create_mask(pred_mask)])\n",
    "\n",
    "        \n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine:\n",
    "    MODEL_PATH = \"weights/\"+model.name+\".h5\"\n",
    "else:\n",
    "    MODEL_PATH = \"weights/\"+model.name+\"_coarse.h5\"\n",
    "\n",
    "model.load_weights(\"weights/\"+model.name+\"_coarse.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(lr=1e-4),\n",
    "    loss = cce_iou_loss, \n",
    "    metrics = ['accuracy', iou_coef]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine:\n",
    "    ES_patience = 10\n",
    "    RLR_patience = 5\n",
    "    EPOCHS = 20\n",
    "else:\n",
    "    ES_patience = 4\n",
    "    RLR_patience = 2\n",
    "    EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    DisplayCallback(),\n",
    "    ModelCheckpoint(MODEL_PATH, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min'),\n",
    "    EarlyStopping(monitor='val_loss', mode='min', patience=ES_patience, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', mode='min', patience=RLR_patience, factor=0.1, min_lr=1e-10, verbose=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSPLITS = 4\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE // SUBSPLITS\n",
    "VALIDATION_STEPS = TEST_LENGTH // BATCH_SIZE // SUBSPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    epochs = (EPOCHS*SUBSPLITS),\n",
    "    validation_data = test_dataset,\n",
    "    callbacks = callbacks,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine:\n",
    "    model.save_weights(PATH_fine)\n",
    "else:\n",
    "    model.save_weights(PATH_coarse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(results, model):\n",
    "        \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.subplot(1,3,1)  \n",
    "    if model.name == \"u2net\":\n",
    "        plt.plot(results.history['d0_loss'], 'r', label='Training loss')\n",
    "        plt.plot(results.history['val_d0_loss'], 'b', label='Validation loss')\n",
    "    else: \n",
    "        plt.plot(results.history['loss'], 'r', label='Training loss')\n",
    "        plt.plot(results.history['val_loss'], 'b', label='Validation loss')\n",
    "    plt.title(\"Loss: \"+model.name, fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    if model.name == \"u2net\":\n",
    "        plt.plot(results.history['d0_accuracy'], 'r', label='Training accuracy')\n",
    "        plt.plot(results.history['val_d0_accuracy'], 'b', label='Validation accuracy')\n",
    "    else:\n",
    "        plt.plot(results.history['accuracy'], 'r', label='Training accuracy')\n",
    "        plt.plot(results.history['val_accuracy'], 'b', label='Validation accuracy')\n",
    "    plt.title('Accuracy: '+model.name, fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    if model.name == \"u2net\":\n",
    "        plt.plot(results.history['d0_iou_coef'], 'r', label='IoU coefficient')\n",
    "        plt.plot(results.history['val_d0_iou_coef'], 'b', label='Validation IoU coefficient')\n",
    "    else:\n",
    "        plt.plot(results.history['iou_coef'], 'r', label='IoU coefficient')\n",
    "        plt.plot(results.history['val_iou_coef'], 'b', label='Validation IoU coefficient')\n",
    "    plt.title('IoU Coefficient: '+model.name, fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "    if fine:\n",
    "        plt.savefig(DATA_ROOT+\"plots/\"+model.name+\"_learning_curves.png\")\n",
    "    else:\n",
    "        plt.savefig(DATA_ROOT+\"plots/\"+model.name+\"_learning_curves_coarse.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_history(results, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_iou(y_true, y_pred):\n",
    "    \"\"\" Absent classes contribute to the class mean as 1.0 \"\"\"\n",
    "    iou = 0.0\n",
    "    smooth = 1.0\n",
    "    iou_class = []\n",
    "    for i in range(1, n_classes):\n",
    "        intersection = K.sum(y_true[:,:,:,i] * y_pred[:,:,:,i], axis=(1,2))\n",
    "        union = K.sum(y_true[:,:,:,i] + y_pred[:,:,:,i], axis=(1,2)) - intersection\n",
    "        iou_temp = K.mean((intersection + smooth) / (union + smooth))\n",
    "        iou_class.append(iou_temp.numpy())\n",
    "        iou = iou + iou_temp\n",
    "    iou_mean = iou / n_classes\n",
    "    return iou_class, iou_mean.numpy()\n",
    "\n",
    "\n",
    "def evaluate_iou(model, dataset, n_samples):\n",
    "    \n",
    "    iou_class_scores = np.zeros((n_samples, n_classes-1))\n",
    "    iou_mean_scores = np.zeros((n_samples,))\n",
    "    \n",
    "    for idx, (image, mask) in enumerate(dataset):\n",
    "        print(\"\\r Predicting {} \\ {} \".format(idx+1, n_samples), end='')\n",
    "        \n",
    "        X = image.numpy()\n",
    "        y_true = np.expand_dims(mask.numpy(), axis=0)\n",
    "        y_pred = model.predict(np.expand_dims(X, axis=0))\n",
    "        if model.name == \"u2net\":\n",
    "            y_pred = y_pred[0]\n",
    "        \n",
    "        iou_class, iou_mean = get_mean_iou(y_true, y_pred)\n",
    "        iou_class_scores[idx] = iou_class\n",
    "        iou_mean_scores[idx] = iou_mean\n",
    "        \n",
    "        if idx == (n_samples-1):\n",
    "            break\n",
    "            \n",
    "    return np.mean(iou_class_scores, axis=0), np.mean(iou_mean_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_class, iou_mean = evaluate_iou(model=model, dataset=test, n_samples=TEST_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"IoU Score: {:.4f}\".format(iou_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iou_trainId(Id2label, n_classes, iou_class, model, iou_mean):\n",
    "    categories = [Id2label[i].category for i in range(n_classes)]\n",
    "    cmap = [color['color'] for color in plt.rcParams['axes.prop_cycle']]\n",
    "    cat_colors = {\n",
    "        'void': 'black',\n",
    "        'flat': cmap[0],\n",
    "        'construction': cmap[1],\n",
    "        'object': cmap[2],\n",
    "        'nature': cmap[3],\n",
    "        'sky': cmap[4],\n",
    "        'human': cmap[5],\n",
    "        'vehicle': cmap[6]\n",
    "    }\n",
    "    colors = [cat_colors[category] for category in categories]\n",
    "\n",
    "    names = [Id2label[i].name for i in range(n_classes)]\n",
    "\n",
    "    plt.figure(figsize=(14,10), dpi=200)\n",
    "    plt.barh(names, iou_class, color=colors)\n",
    "    plt.xlabel(\"IoU Coefficient: \", fontsize=18)\n",
    "    plt.ylabel(\"Class Name\", fontsize=18)\n",
    "    plt.title(\"Class IoU Scores for {} - Average: {:.3f}\".format(model.name, iou_mean), fontsize=22)\n",
    "    plt.xlim([0, 1])\n",
    "    if fine:\n",
    "        plt.savefig(DATA_ROOT+\"plots/\"+model.name+\"_iou_scores.png\")\n",
    "    else:\n",
    "        plt.savefig(DATA_ROOT+\"plots/\"+model.name+\"_iou_scores_coarse.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_iou_catId(Id2label, n_classes, iou_class, model, iou_mean):\n",
    "    categories = [Id2label[i+1].category for i in range(n_classes-1)]\n",
    "    cat_colors = {\n",
    "        'void': colors.to_hex(list(np.array(catId2label[0].color)/255)),\n",
    "        'flat': colors.to_hex(list(np.array(catId2label[1].color)/255)),\n",
    "        'construction': colors.to_hex(list(np.array(catId2label[2].color)/255)),\n",
    "        'object': colors.to_hex(list(np.array(catId2label[3].color)/255)),\n",
    "        'nature': colors.to_hex(list(np.array(catId2label[4].color)/255)),\n",
    "        'sky': colors.to_hex(list(np.array(catId2label[5].color)/255)),\n",
    "        'human': colors.to_hex(list(np.array(catId2label[6].color)/255)),\n",
    "        'vehicle': colors.to_hex(list(np.array(catId2label[7].color)/255))\n",
    "    }\n",
    "    _colors = [cat_colors[category] for category in categories]\n",
    "\n",
    "    plt.figure(figsize=(14,10))\n",
    "    plt.barh(categories, iou_class, color=_colors)\n",
    "    plt.xlabel(\"IoU Coefficient\", fontsize=18)\n",
    "    plt.ylabel(\"Category Name\", fontsize=18)\n",
    "    plt.title(\"Category IoU Scores for {} - Average: {:.3f}\".format(model.name, iou_mean), fontsize=22)\n",
    "    plt.xlim([0, 1])\n",
    "    if fine:\n",
    "        plt.savefig(DATA_ROOT+\"plots/\"+model.name+\"_iou_scores.png\")\n",
    "    else:\n",
    "        plt.savefig(DATA_ROOT+\"plots/\"+model.name+\"_iou_scores_coarse.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_iou_trainId(Id2label=trainId2label, n_classes=n_classes, iou_class=iou_class, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iou_catId(Id2label=catId2label, n_classes=n_classes, iou_class=iou_class, model=model, iou_mean=iou_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
